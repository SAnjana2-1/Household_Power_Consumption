# -*- coding: utf-8 -*-
"""svm .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-CbDeGVJ7kB2eoJXrltXZPNY-Udk_z4Y

**decision tree**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB

df1 = pd.read_csv('/content/household_power_consumption.txt', sep=';',
                 parse_dates={'Datetime': ['Date', 'Time']},
                 infer_datetime_format=True, low_memory=False)

df1.replace('?', pd.NA, inplace=True)

df1.dropna(inplace=True)
df=df1.head(100000)
df['Global_active_power'] = df['Global_active_power'].astype(float)

# Create a binary target variable
median_consumption = df['Global_active_power'].median()
df['High_consumption'] = (df['Global_active_power'] > median_consumption).astype(int)
df.drop(['Global_active_power'], axis=1, inplace=True)

# Load and preprocess your dataset
X = df.drop(['High_consumption', 'Datetime'], axis=1)
y = df['High_consumption']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Decision Tree Classifier
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train_scaled, y_train)

# Make predictions
y_pred_dt = dt_classifier.predict(X_test_scaled)

# Evaluate the model
accuracy_dt = accuracy_score(y_test, y_pred_dt)
report_dt = classification_report(y_test, y_pred_dt)

print(f"Decision Tree Accuracy: {accuracy_dt}")
print(f"Decision Tree Classification Report: \n{report_dt}")

# Confusion Matrix
conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)
plt.figure(figsize=(5, 4))
sns.heatmap(conf_matrix_dt, annot=True, fmt='d', cmap='Blues', xticklabels=['Low', 'High'], yticklabels=['Low', 'High'])
plt.title('Decision Tree Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

# Limit the visualization depth and adjust the figure size for a clearer view
plt.figure(figsize=(12, 6))  # Set a smaller figure size
plot_tree(model,
          feature_names=X_train.columns,
          class_names=['Low Rental', 'High Rental'],
          filled=True,
          rounded=True,
          fontsize=8,
          max_depth=3)  # Adjust to show the top 3 levels for clarity
plt.title('Simplified Decision Tree Visualization')
plt.show()

"""**SVM **"""

# Load and preprocess your dataset
X = df.drop(['High_consumption', 'Datetime'], axis=1)
y = df['High_consumption']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Support Vector Machine Classifier
svm_classifier = SVC(random_state=42)
svm_classifier.fit(X_train_scaled, y_train)

# Make predictions
y_pred_svm = svm_classifier.predict(X_test_scaled)

# Evaluate the model
accuracy_svm = accuracy_score(y_test, y_pred_svm)
report_svm = classification_report(y_test, y_pred_svm)

print(f"SVM Accuracy: {accuracy_svm}")
print(f"SVM Classification Report: \n{report_svm}")

# Confusion Matrix
conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)
plt.figure(figsize=(5, 4))
sns.heatmap(conf_matrix_svm, annot=True, fmt='d', cmap='Blues', xticklabels=['Low', 'High'], yticklabels=['Low', 'High'])
plt.title('SVM Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""**navie bayers**"""

# Load and preprocess your dataset
X = df.drop(['High_consumption', 'Datetime'], axis=1)
y = df['High_consumption']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Naive Bayes Classifier
nb_classifier = GaussianNB()
nb_classifier.fit(X_train_scaled, y_train)

# Make predictions
y_pred_nb = nb_classifier.predict(X_test_scaled)

# Evaluate the model
accuracy_nb = accuracy_score(y_test, y_pred_nb)
report_nb = classification_report(y_test, y_pred_nb)

print(f"Naive Bayes Accuracy: {accuracy_nb}")
print(f"Naive Bayes Classification Report: \n{report_nb}")

# Confusion Matrix
conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)
plt.figure(figsize=(5, 3))
sns.heatmap(conf_matrix_nb, annot=True, fmt='d', cmap='Blues', xticklabels=['Low', 'High'], yticklabels=['Low', 'High'])
plt.title('Naive Bayes Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""bernoulli navie bayes"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.naive_bayes import BernoulliNB
from sklearn.preprocessing import Binarizer

# Load and preprocess your dataset
X = df.drop(['High_consumption', 'Datetime'], axis=1)
y = df['High_consumption']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Since Bernoulli Naive Bayes is for binary features, ensure your features are binary (0 or 1)
# Convert all numeric columns in X_train and X_test to numeric type
for column in X_train.select_dtypes(include=['object']).columns:
    try:
        X_train[column] = pd.to_numeric(X_train[column])
        X_test[column] = pd.to_numeric(X_test[column])
    except ValueError:
        print(f"Could not convert column '{column}' to numeric. It might contain non-numeric values.")
        # Handle the non-numeric values in the column (e.g., imputation, removal)

binarizer = Binarizer()
X_train_binarized = binarizer.fit_transform(X_train)
X_test_binarized = binarizer.transform(X_test)

# You can skip binarization if your features are already binary
X_train_binarized = (X_train > 0).astype(int)
X_test_binarized = (X_test > 0).astype(int)

# Bernoulli Naive Bayes Classifier
bnb_classifier = BernoulliNB()
bnb_classifier.fit(X_train_binarized, y_train)

# Make predictions
y_pred_bnb = bnb_classifier.predict(X_test_binarized)

# Evaluate the model
accuracy_bnb = accuracy_score(y_test, y_pred_bnb)
report_bnb = classification_report(y_test, y_pred_bnb)

print(f"Bernoulli Naive Bayes Accuracy: {accuracy_bnb}")
print(f"Bernoulli Naive Bayes Classification Report: \n{report_bnb}")

# Confusion Matrix
conf_matrix_bnb = confusion_matrix(y_test, y_pred_bnb)
plt.figure(figsize=(5, 4))
sns.heatmap(conf_matrix_bnb, annot=True, fmt='d', cmap='Blues', xticklabels=['Low', 'High'], yticklabels=['Low', 'High'])
plt.title('Bernoulli Naive Bayes Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""**PCA**"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# Prepare your features (X) and labels (y)
X = df.drop(['High_consumption', 'Datetime'], axis=1)
y = df['High_consumption']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Apply PCA
pca = PCA(n_components=2)  # Reduce to 2 dimensions for visualization
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Create a DataFrame with PCA results for visualization
pca_df = pd.DataFrame(data=X_train_pca, columns=['Principal Component 1', 'Principal Component 2'])
pca_df['Target'] = y_train.reset_index(drop=True)

# Visualize the PCA results
plt.figure(figsize=(10, 6))
sns.scatterplot(data=pca_df, x='Principal Component 1', y='Principal Component 2', hue='Target', palette='viridis')
plt.title('PCA of the Dataset')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend(title='High Consumption')
plt.grid()
plt.show()

# Explained Variance Ratio
explained_variance = pca.explained_variance_ratio_
print(f"Explained variance ratio by each principal component: {explained_variance}")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report

# Creating a DataFrame from the provided data
data = {
    'Date': ['16/12/2006'] * 5,
    'Time': ['17:24:00', '17:25:00', '17:26:00', '17:27:00', '17:28:00'],
    'Global_active_power': [4.216, 5.360, 5.374, 5.388, 3.666],
    'Global_reactive_power': [0.418, 0.436, 0.498, 0.502, 0.528],
    'Voltage': [234.840, 233.630, 233.290, 233.740, 235.680],
    'Global_intensity': [18.400, 23.000, 23.000, 23.000, 15.800],
    'Sub_metering_1': [0.000, 0.000, 0.000, 0.000, 0.000],
    'Sub_metering_2': [1.000, 1.000, 2.000, 1.000, 1.000],
    'Sub_metering_3': [17.000, 16.000, 17.000, 17.000, 17.000]
}

df = pd.DataFrame(data)
df['High_consumption'] = (df['Global_active_power'] > 5).astype(int)

X = df[['Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']]
y = df['High_consumption']

# Splitting the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Gini Impurity Calculation
def gini_impurity(y):
    classes = y.value_counts(normalize=True)
    return 1 - sum(classes**2)

gini_before = gini_impurity(y)
print(f"Gini Impurity Before Split: {gini_before:.4f}")

# Fitting the Decision Tree Classifier
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train, y_train)

# Making Predictions
y_pred = dt_classifier.predict(X_test)

# Evaluating the model
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print(f"Classification Report:\n{report}")